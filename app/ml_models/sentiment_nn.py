import re
import numpy as np
from typing import Dict, List, Tuple
import pickle
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import Callback
import time

class TrainingProgressCallback(Callback):
    """Callback para monitorear el progreso del entrenamiento"""
    def __init__(self):
        self.start_time = None
        self.epoch_times = []
        import sys
        self.stdout = sys.stdout
    
    def _print_and_flush(self, message):
        """Imprimir y hacer flush inmediatamente"""
        print(message)
        self.stdout.flush()
    
    def on_train_begin(self, logs=None):
        self.start_time = time.time()
        self._print_and_flush(f"‚è±Ô∏è [DEBUG] Entrenamiento comenz√≥ a las {time.strftime('%H:%M:%S')}")
        self._print_and_flush(f"üîç [DEBUG] Callback on_train_begin ejecutado correctamente")
    
    def on_epoch_begin(self, epoch, logs=None):
        epoch_start = time.time()
        self._print_and_flush(f"üîÑ [DEBUG] √âpoca {epoch + 1} comenzando a las {time.strftime('%H:%M:%S')}...")
        self.current_epoch_start = epoch_start
    
    def on_batch_begin(self, batch, logs=None):
        # Log cada 5 batches para no saturar, pero ver progreso
        if batch % 5 == 0 or batch == 0:
            self._print_and_flush(f"üîç [DEBUG] Batch {batch} comenzando...")
    
    def on_batch_end(self, batch, logs=None):
        # Log cada 5 batches para no saturar, pero ver progreso
        if batch % 5 == 0 or batch == 0:
            loss = logs.get('loss', 'N/A')
            acc = logs.get('accuracy', 'N/A')
            self._print_and_flush(f"üîç [DEBUG] Batch {batch} completado - loss: {loss}, accuracy: {acc}")
    
    def on_epoch_end(self, epoch, logs=None):
        epoch_time = time.time() - self.current_epoch_start
        self.epoch_times.append(epoch_time)
        loss = logs.get('loss', 'N/A')
        accuracy = logs.get('accuracy', 'N/A')
        val_loss = logs.get('val_loss', 'N/A')
        val_accuracy = logs.get('val_accuracy', 'N/A')
        self._print_and_flush(f"‚úÖ [DEBUG] √âpoca {epoch + 1} completada en {epoch_time:.2f}s - loss: {loss:.4f}, accuracy: {accuracy:.4f}, val_loss: {val_loss}, val_accuracy: {val_accuracy}")
    
    def on_train_end(self, logs=None):
        total_time = time.time() - self.start_time
        self._print_and_flush(f"‚è±Ô∏è [DEBUG] Entrenamiento terminado en {total_time:.2f}s total")
        if self.epoch_times:
            avg_time = sum(self.epoch_times) / len(self.epoch_times)
            self._print_and_flush(f"üìä [DEBUG] Tiempo promedio por √©poca: {avg_time:.2f}s")
        else:
            self._print_and_flush(f"‚ö†Ô∏è [DEBUG] No se registraron √©pocas completadas")

class SentimentNeuralNetwork:
    def __init__(self, max_words=5000, max_len=100):
        # Red neuronal LSTM basada en texto - Optimizado para p√°rrafos largos
        # max_words: 5000 (vocabulario amplio para mejor comprensi√≥n)
        # max_len: 100 (longitud suficiente para p√°rrafos completos)
        self.max_words = max_words
        self.max_len = max_len
        self.tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
        self.label_encoder = LabelEncoder()
        self.model = None
        self.is_trained = False
        
    def clean_text(self, text: str) -> str:
        """
        Limpieza de texto mejorada con normalizaci√≥n y correcci√≥n de encoding.
        
        ‚ö†Ô∏è IMPORTANTE: Este m√©todo SOLO limpia el texto (corrige encoding, normaliza).
        NO clasifica sentimientos. La clasificaci√≥n se hace 100% por la red neuronal LSTM.
        
        El diccionario 'encoding_fixes' es SOLO para corregir problemas de encoding
        de archivos CSV/Excel (ej: √É¬© -> √©). NO es un diccionario de sentimientos.
        """
        if not text:
            return ""
        
        # ‚ö†Ô∏è SOLO CORRECCI√ìN DE ENCODING - NO CLASIFICACI√ìN DE SENTIMIENTOS
        # Esto corrige problemas cuando Excel guarda UTF-8 pero se lee como Latin-1
        # Ejemplo: "√É¬©" (mal codificado) -> "√©" (correcto)
        # Esto NO afecta la clasificaci√≥n de sentimientos, solo limpia el texto
        encoding_fixes = {
            # Caracteres mal codificados m√°s comunes (UTF-8 mal le√≠do como Latin-1)
            '√É¬°': '√°', '√É¬©': '√©', '√É¬≠': '√≠', '√É¬≥': '√≥', '√É¬∫': '√∫',
            '√É¬±': '√±', '√É¬º': '√º', 
            '√É': '√Å', '√É‚Ä∞': '√â', '√É': '√ç', '√É"': '√ì', '√É≈°': '√ö',
            '√É': '√ë', '√É≈ì': '√ú',
            # Caracteres raros que aparecen en Excel
            '√¢‚Ç¨‚Ñ¢': "'", '√¢‚Ç¨≈ì': '"', '√¢‚Ç¨': '"', '√¢‚Ç¨"': '‚Äî', '√¢‚Ç¨"': '‚Äì',
            # Limpiar caracteres de control
            '\ufeff': '',  # BOM de UTF-8
            '\x00': '',  # Null bytes
        }
        
        # Aplicar correcciones de encoding (SOLO limpieza, NO clasificaci√≥n)
        for wrong, correct in encoding_fixes.items():
            text = text.replace(wrong, correct)
        
        # Intentar correcci√≥n autom√°tica de encoding si detectamos problemas
        if '√É' in text:
            try:
                # Intentar decodificar como Latin-1 y recodificar como UTF-8
                text = text.encode('latin-1', errors='ignore').decode('utf-8', errors='ignore')
            except:
                pass
        
        # Convertir a min√∫sculas
        text = text.lower()
        
        # Normalizar tildes y caracteres especiales
        # IMPORTANTE: El modelo fue entrenado eliminando tildes para normalizar
        # "atenci√≥n" y "atencion" se tratan igual, lo cual es √∫til para el modelo
        replacements = {
            '√°': 'a', '√©': 'e', '√≠': 'i', '√≥': 'o', '√∫': 'u',
            '√±': 'n', '√º': 'u'
        }
        for old, new in replacements.items():
            text = text.replace(old, new)
        
        # Eliminar URLs
        text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
        
        # Eliminar menciones y hashtags
        text = re.sub(r'@\w+|#\w+', '', text)
        
        # Eliminar caracteres especiales excepto letras, n√∫meros y espacios
        text = re.sub(r'[^a-z0-9\s]', ' ', text)
        
        # Eliminar espacios m√∫ltiples
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()
    
    def prepare_data(self, texts: List[str], labels: List[str] = None) -> Tuple:
        """
        Preparar datos para entrenamiento o predicci√≥n.
        
        ‚ö†Ô∏è IMPORTANTE: Este m√©todo SOLO convierte texto a n√∫meros.
        NO clasifica sentimientos. La clasificaci√≥n se hace 100% por la red neuronal LSTM.
        
        Flujo:
        1. Limpia el texto (encoding, normalizaci√≥n)
        2. Tokenizer: Convierte palabras a n√∫meros (ej: "excelente" -> 5)
           - Esto es necesario porque las redes neuronales solo procesan n√∫meros
           - NO es un diccionario de sentimientos, solo un mapeo palabra->n√∫mero
        3. Label encoder: Convierte etiquetas a n√∫meros (ej: "positivo" -> 0)
           - Solo para entrenamiento, NO para predicci√≥n
        4. La red neuronal LSTM hace la clasificaci√≥n real en predict()
        """
        # Logging m√≠nimo para ahorrar memoria durante predicci√≥n
        if labels:
            print(f"üîç [DEBUG] prepare_data() entrenamiento: {len(texts)} textos")
        # Si no hay labels, es predicci√≥n - logging m√≠nimo
        
        if not texts:
            raise ValueError("La lista de textos no puede estar vac√≠a")
        
        # 1. Limpiar textos (SOLO limpieza, NO clasificaci√≥n)
        cleaned_texts = [self.clean_text(text) if text else "" for text in texts]
        
        # 2. Tokenizar: Convertir palabras a n√∫meros
        # ‚ö†Ô∏è El tokenizer.word_index es un VOCABULARIO (mapeo palabra->n√∫mero)
        # NO es un diccionario de sentimientos. Ejemplo: {"excelente": 5, "malo": 12}
        # Las redes neuronales necesitan n√∫meros, no texto
        if labels:
            # Si hay etiquetas, estamos entrenando, ajustar tokenizer
            self.tokenizer.fit_on_texts(cleaned_texts)
            if len(self.tokenizer.word_index) > 0:
                print(f"üîç [DEBUG] Tokenizer entrenado: vocab_size={len(self.tokenizer.word_index)}")
        elif not hasattr(self.tokenizer, 'word_index') or not self.tokenizer.word_index:
            raise ValueError("El tokenizer no est√° entrenado. Debe entrenar el modelo primero.")
        
        # Convertir textos a secuencias de n√∫meros
        # Ejemplo: "excelente servicio" -> [5, 23] (n√∫meros, no sentimientos)
        sequences = self.tokenizer.texts_to_sequences(cleaned_texts)
        
        # Asegurar que todas las secuencias tengan al menos un elemento (OOV token)
        sequences = [seq if seq else [1] for seq in sequences]
        
        # Hacer padding (rellenar secuencias para que tengan la misma longitud)
        padded_sequences = pad_sequences(sequences, maxlen=self.max_len, padding='post', truncating='post')
        
        if labels:
            # 3. Label encoder: Convertir etiquetas a n√∫meros (SOLO para entrenamiento)
            # Ejemplo: "positivo" -> 0, "negativo" -> 1, "neutral" -> 2
            # ‚ö†Ô∏è Esto NO clasifica, solo convierte etiquetas a n√∫meros para entrenar
            encoded_labels = self.label_encoder.fit_transform(labels)
            # Mostrar distribuci√≥n de etiquetas (logging m√≠nimo)
            unique_encoded, counts_encoded = np.unique(encoded_labels, return_counts=True)
            label_names_encoded = self.label_encoder.inverse_transform(unique_encoded)
            print(f"üîç [DEBUG] Datos preparados: shape={padded_sequences.shape}, Distribuci√≥n: {dict(zip(label_names_encoded, counts_encoded))}")
            return padded_sequences, encoded_labels
        
        return padded_sequences
    
    def build_model(self, vocab_size: int, num_classes: int):
        """
        Construir red neuronal LSTM basada en texto.
        
        ‚ö†Ô∏è IMPORTANTE: Esta es una RED NEURONAL REAL (LSTM) que aprende patrones.
        NO hay reglas hardcodeadas, NO hay diccionarios de sentimientos.
        
        Arquitectura de la red neuronal:
        1. Embedding: Convierte n√∫meros de palabras a vectores (representaci√≥n sem√°ntica)
        2. LSTM: Procesa secuencias de palabras y aprende patrones temporales
        3. Dense + Dropout: Capas de aprendizaje que extraen caracter√≠sticas
        4. Dense (softmax): Capa de salida que clasifica en 3 clases (positivo/negativo/neutral)
        
        La red neuronal APRENDE durante el entrenamiento qu√© combinaciones de palabras
        indican sentimientos positivos, negativos o neutrales.
        """
        print(f"üîç [DEBUG] Construyendo modelo: vocab_size={vocab_size}, num_classes={num_classes}")
        print(f"üîç [DEBUG] Par√°metros del modelo: max_words={self.max_words}, max_len={self.max_len}")
        
        # üß† RED NEURONAL LSTM - Aprende patrones, no reglas hardcodeadas
        from tensorflow.keras.initializers import GlorotUniform
        
        # Modelo optimizado para mejor aprendizaje (aumentado de tama√±o m√≠nimo)
        # Balance entre memoria y capacidad de aprendizaje
        effective_vocab_size = min(vocab_size + 1, self.max_words + 1)
        model = Sequential([
            # Capa 1: Embedding - Convierte n√∫meros a vectores sem√°nticos
            Embedding(effective_vocab_size, 16, mask_zero=True),  # 16 dimensiones (aumentado de 6)
            # Capa 2: LSTM - Procesa secuencias y aprende patrones temporales
            LSTM(8, dropout=0.2, recurrent_dropout=0.2),  # 8 unidades (aumentado de 3) con dropout
            # Capa 3: Dense - Extrae caracter√≠sticas aprendidas
            Dense(16, activation='relu'),   # 16 unidades (aumentado de 6)
            # Capa 4: Dropout - Previene sobreajuste
            Dropout(0.3),  # Dropout para regularizaci√≥n
            # Capa 5: Dense (softmax) - Clasifica en 3 clases (positivo/negativo/neutral)
            Dense(num_classes, activation='softmax')  # Salida (3 clases)
        ])
        print(f"üîç [DEBUG] Vocabulario: {effective_vocab_size}, Modelo mejorado: Embedding(16), LSTM(8), Dense(16)")
        
        print(f"üîç [DEBUG] Modelo construido, compilando...")
        # Compilar modelo neuronal con learning rate m√°s conservador para mejor convergencia
        from tensorflow.keras.optimizers import Adam
        optimizer = Adam(learning_rate=0.001)  # Learning rate m√°s conservador (0.001) para mejor convergencia
        model.compile(
            optimizer=optimizer,
            loss='sparse_categorical_crossentropy',
            metrics=['accuracy'],
            run_eagerly=False  # Deshabilitar eager mode para mejor rendimiento y convergencia
        )
        
        # NO contar par√°metros aqu√≠ - el modelo a√∫n no est√° "built"
        # Los par√°metros se contar√°n despu√©s del primer fit() cuando el modelo se construya autom√°ticamente
        print(f"üîç [DEBUG] Modelo compilado correctamente (run_eagerly=False)")
        
        return model
    
    def train(self, texts: List[str], labels: List[str], epochs=10, batch_size=32):
        """Entrenar modelo - Versi√≥n ULTRA-LIGERA para Render (512 MB limit)"""
        import tensorflow as tf
        import gc  # Para limpiar memoria
        
        print(f"üìä Preparando datos: {len(texts)} textos, {len(set(labels))} clases")
        X, y = self.prepare_data(texts, labels)
        
        # Mostrar distribuci√≥n de etiquetas ANTES de reducir
        unique_labels, counts = np.unique(y, return_counts=True)
        label_names = self.label_encoder.inverse_transform(unique_labels)
        print(f"üîç [DEBUG] Distribuci√≥n de etiquetas ANTES de reducir:")
        for label_name, count in zip(label_names, counts):
            print(f"   - {label_name}: {count} muestras")
        
        # USAR m√°s datos para mejor aprendizaje (pero sin exceder memoria)
        # Aumentar muestras para mejor precisi√≥n con p√°rrafos largos
        max_samples = 180  # Usar 180 muestras para mejor aprendizaje (aumentado de 120 para incluir p√°rrafos largos)
        if len(X) > max_samples:
            print(f"‚ö†Ô∏è Reduciendo datos de {len(X)} a {max_samples} para ahorrar memoria...")
            
            # MEZCLAR datos ANTES de reducir para mantener balance de clases
            indices = np.arange(len(X))
            np.random.seed(42)  # Semilla fija para reproducibilidad
            np.random.shuffle(indices)
            X_shuffled = X[indices]
            y_shuffled = y[indices]
            
            # Asegurar balance de clases al reducir
            unique_labels_all = np.unique(y_shuffled)
            num_classes_available = len(unique_labels_all)
            samples_per_class = max_samples // num_classes_available
            min_samples_per_class = max(1, samples_per_class - 2)  # Al menos samples_per_class-2 por clase
            
            print(f"üîç [DEBUG] Intentando balancear: ~{samples_per_class} muestras por clase de {num_classes_available} clases")
            
            # Recopilar muestras balanceadas
            X_balanced = []
            y_balanced = []
            samples_taken_per_class = {int(label): 0 for label in unique_labels_all}
            used_indices = set()
            
            # Primero, tomar muestras balanceadas de cada clase
            for label in unique_labels_all:
                label_int = int(label)
                label_indices = np.where(y_shuffled == label)[0]
                np.random.shuffle(label_indices)
                
                for idx in label_indices[:min_samples_per_class]:
                    if len(X_balanced) >= max_samples:
                        break
                    if idx not in used_indices:
                        X_balanced.append(X_shuffled[idx])
                        y_balanced.append(y_shuffled[idx])
                        used_indices.add(idx)
                        samples_taken_per_class[label_int] += 1
                
                if len(X_balanced) >= max_samples:
                    break
            
            # Si a√∫n hay espacio, tomar muestras adicionales de manera aleatoria
            remaining_indices = [i for i in range(len(X_shuffled)) if i not in used_indices]
            np.random.shuffle(remaining_indices)
            
            for idx in remaining_indices:
                if len(X_balanced) >= max_samples:
                    break
                X_balanced.append(X_shuffled[idx])
                y_balanced.append(y_shuffled[idx])
                used_indices.add(idx)
            
            X = np.array(X_balanced)
            y = np.array(y_balanced)
            
            # Validar balance de clases DESPU√âS de reducir
            unique_labels_reduced, counts_reduced = np.unique(y, return_counts=True)
            label_names_reduced = self.label_encoder.inverse_transform(unique_labels_reduced)
            print(f"üîç [DEBUG] Distribuci√≥n de etiquetas DESPU√âS de reducir (balanceado):")
            for label_name, count in zip(label_names_reduced, counts_reduced):
                print(f"   - {label_name}: {count} muestras")
        else:
            # MEZCLAR datos antes de entrenar para mejor aprendizaje
            print("üîç [DEBUG] Mezclando datos antes de entrenar...")
            indices = np.arange(len(X))
            np.random.seed(42)  # Semilla fija para reproducibilidad
            np.random.shuffle(indices)
            X = X[indices]
            y = y[indices]
            print(f"‚úÖ [DEBUG] Datos mezclados: {len(X)} muestras")
        
        # SIEMPRE entrenar sin validaci√≥n para m√°xima velocidad y menor uso de memoria
        # Con pocos datos, la validaci√≥n no es necesaria y solo ralentiza
        X_train, y_train = X, y
        X_val, y_val = X, y
        use_validation = False
        print(f"üîç [DEBUG] Entrenando SIN validaci√≥n para m√°xima velocidad y menor memoria")
        
        vocab_size = len(self.tokenizer.word_index)
        num_classes = len(self.label_encoder.classes_)
        print(f"üìä Vocabulario: {vocab_size} palabras, Clases: {num_classes}")
        print(f"üìä Datos entrenamiento: {len(X_train)}, Validaci√≥n: {len(X_val) if use_validation else 'N/A'}")
        
        # Validar balance de clases en datos de entrenamiento
        unique_labels_train, counts_train = np.unique(y_train, return_counts=True)
        label_names_train = self.label_encoder.inverse_transform(unique_labels_train)
        print(f"üîç [DEBUG] Distribuci√≥n de etiquetas en datos de ENTRENAMIENTO:")
        for label_name, count in zip(label_names_train, counts_train):
            print(f"   - {label_name}: {count} muestras")
        
        # Verificar que haya al menos una muestra de cada clase en entrenamiento
        if len(unique_labels_train) < num_classes:
            print(f"‚ö†Ô∏è [DEBUG] ADVERTENCIA: Solo hay {len(unique_labels_train)} clases en entrenamiento, esperadas {num_classes}")
            print(f"‚ö†Ô∏è [DEBUG] Esto puede afectar la precisi√≥n del modelo")
        else:
            print(f"‚úÖ [DEBUG] Todas las clases ({num_classes}) est√°n representadas en los datos de entrenamiento")
        
        # Limpiar memoria ANTES de construir modelo (CR√çTICO para Render 512 MB)
        print("üîç [DEBUG] Limpiando memoria antes de construir modelo...")
        import tensorflow as tf
        tf.keras.backend.clear_session()  # Limpiar sesi√≥n de Keras antes
        gc.collect()  # Recolectar basura
        print("‚úÖ [DEBUG] Memoria limpiada antes de construir modelo")
        
        print("üîç [DEBUG] Construyendo modelo...")
        build_start = time.time()
        self.model = self.build_model(vocab_size, num_classes)
        build_time = time.time() - build_start
        print(f"‚úÖ [DEBUG] Modelo construido en {build_time:.2f}s")
        
        # OPTIMIZACI√ìN: Balance entre memoria y aprendizaje
        actual_epochs = 15  # Aumentar √©pocas para mejor aprendizaje (aumentado de 5)
        # Batch size balanceado para mejor aprendizaje
        actual_batch_size = min(8, len(X_train))  # Batch size aumentado para mejor estabilidad (aumentado de 3)
        print(f"üîç [DEBUG] Batch size: {actual_batch_size}, √âpocas: {actual_epochs} (optimizado para mejor aprendizaje)")
        
        print(f"üöÄ Iniciando entrenamiento: {actual_epochs} √©pocas (reducido de {epochs}), batch_size={actual_batch_size} (ajustado de {batch_size})")
        print(f"üìä Datos de entrenamiento: {len(X_train)} muestras")
        print(f"üìä Shape de X_train: {X_train.shape}, Shape de y_train: {y_train.shape}")
        
        # Callbacks simples para entrenamiento
        fit_kwargs = {
            'epochs': actual_epochs,
            'batch_size': actual_batch_size,
            'verbose': 1,  # Mostrar progress (se cambia a 1 en fit())
            'callbacks': []  # Sin callbacks complejos para velocidad
        }
        
        # NO construir modelo expl√≠citamente - ahorra memoria
        # El modelo se construir√° autom√°ticamente en el primer fit()
        print("üîç [DEBUG] El modelo se construir√° autom√°ticamente en el primer fit()")
        
        # Entrenamiento SIMPLIFICADO - sin validaci√≥n, sin callbacks, m√°ximo velocidad
        print("üîç [DEBUG] Llamando a model.fit() sin validaci√≥n...")
        print(f"üîç [DEBUG] X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
        print(f"üîç [DEBUG] Par√°metros: epochs={actual_epochs}, batch_size={actual_batch_size}, samples={len(X_train)}")
        
        # Flush stdout para asegurar que los logs se muestren
        import sys
        sys.stdout.flush()
        
        print(f"üöÄ [DEBUG] INICIANDO model.fit() - entrenamiento con {actual_epochs} √©pocas...")
        sys.stdout.flush()
        
        fit_start = time.time()
        history = None
        try:
            # Entrenamiento con verbose para ver accuracy
            fit_kwargs['verbose'] = 1  # Mostrar progress para ver si est√° aprendiendo
            history = self.model.fit(X_train, y_train, **fit_kwargs)
            fit_time = time.time() - fit_start
            print(f"‚úÖ [DEBUG] model.fit() completado en {fit_time:.2f}s")
            
            # Verificar accuracy final
            if hasattr(history, 'history') and 'accuracy' in history.history:
                final_accuracy = history.history['accuracy'][-1]
                final_loss = history.history['loss'][-1] if 'loss' in history.history else None
                print(f"üìä [DEBUG] Accuracy final del entrenamiento: {final_accuracy:.4f}")
                if final_loss:
                    print(f"üìä [DEBUG] Loss final del entrenamiento: {final_loss:.4f}")
                if final_accuracy < 0.6:
                    print(f"‚ö†Ô∏è [DEBUG] ADVERTENCIA: Accuracy baja ({final_accuracy:.4f}), el modelo podr√≠a no estar aprendiendo bien")
                elif final_accuracy < 0.8:
                    print(f"‚úÖ [DEBUG] Accuracy aceptable: {final_accuracy:.4f} (mejorable pero funcional)")
                else:
                    print(f"‚úÖ [DEBUG] Accuracy excelente: {final_accuracy:.4f}")
            else:
                print(f"‚ö†Ô∏è [DEBUG] No se pudo obtener accuracy del historial")
            
            sys.stdout.flush()
        except Exception as fit_error:
            fit_time = time.time() - fit_start
            print(f"‚ùå [DEBUG] ERROR en model.fit() despu√©s de {fit_time:.2f}s: {str(fit_error)}")
            print(f"üîç [DEBUG] Tipo de error: {type(fit_error).__name__}")
            import traceback
            traceback.print_exc()
            sys.stdout.flush()
            raise
        
        # Ahora s√≠ podemos contar los par√°metros (el modelo ya est√° "built" despu√©s del fit)
        try:
            total_params = self.model.count_params()
            print(f"üìä [DEBUG] Modelo entrenado - Total de par√°metros: {total_params:,}")
        except Exception as e:
            print(f"‚ö†Ô∏è [DEBUG] No se pudo contar par√°metros: {e}")
        
        print(f"‚úÖ Entrenamiento completado (sin validaci√≥n)")
        
        # Validar que el modelo est√© correctamente entrenado
        print("üîç [DEBUG] Validando modelo despu√©s del entrenamiento...")
        if self.model is None:
            raise ValueError("El modelo no existe despu√©s del entrenamiento")
        
        print("üîç [DEBUG] Marcando modelo como entrenado...")
        self.is_trained = True
        print(f"‚úÖ [DEBUG] Modelo marcado como entrenado: is_trained={self.is_trained}")
        print(f"üîç [DEBUG] Modelo existe: {self.model is not None}")
        print(f"üîç [DEBUG] Tokenizer tiene word_index: {hasattr(self.tokenizer, 'word_index') and len(self.tokenizer.word_index) > 0}")
        print(f"üîç [DEBUG] Label encoder tiene classes: {hasattr(self.label_encoder, 'classes_') and len(self.label_encoder.classes_) > 0}")
        
        # NO hacer prueba r√°pida para ahorrar memoria
        # El modelo ya est√° entrenado y validado por el accuracy del entrenamiento
        print("üîç [DEBUG] Prueba r√°pida omitida para ahorrar memoria")
        
        # Limpiar memoria despu√©s de validar (CR√çTICO para Render 512 MB)
        print("üîç [DEBUG] Limpiando memoria despu√©s de entrenar...")
        # NO eliminar history aqu√≠ porque se necesita devolver
        # Solo limpiar otras variables temporales
        gc.collect()  # Recolectar basura de Python
        print("‚úÖ [DEBUG] Memoria limpiada (modelo preservado)")
        
        # Devolver history si existe, sino devolver None
        return history if history is not None else None
    
    def predict(self, texts: List[str]) -> List[Dict]:
        """
        Predecir sentimiento usando SOLO red neuronal LSTM.
        
        ‚ö†Ô∏è IMPORTANTE: Esta funci√≥n usa 100% red neuronal LSTM para clasificar.
        NO hay reglas hardcodeadas, NO hay diccionarios de sentimientos.
        
        Flujo de predicci√≥n:
        1. Limpia el texto (encoding, normalizaci√≥n)
        2. Tokeniza (convierte palabras a n√∫meros)
        3. Pasa por la red neuronal LSTM (aqu√≠ se hace la clasificaci√≥n)
        4. La red neuronal devuelve probabilidades (ej: [0.1, 0.8, 0.1] = negativo)
        5. Se convierte el n√∫mero de clase a etiqueta (ej: 1 -> "negativo")
        
        La clasificaci√≥n real ocurre en la l√≠nea: predictions = self.model.predict(X)
        La red neuronal LSTM aprendi√≥ los patrones durante el entrenamiento.
        """
        # Validaci√≥n r√°pida (sin logs para mejor rendimiento)
        if not self.is_trained or not self.model:
            raise ValueError("El modelo no est√° listo. Por favor, espera unos momentos.")
        
        if not hasattr(self.tokenizer, 'word_index') or not self.tokenizer.word_index:
            raise ValueError("El tokenizer no est√° listo. Por favor, espera unos momentos.")
        
        if not hasattr(self.label_encoder, 'classes_') or len(self.label_encoder.classes_) == 0:
            raise ValueError("El label encoder no est√° listo. Por favor, espera unos momentos.")
        
        if not texts:
            raise ValueError("La lista de textos no puede estar vac√≠a")
        
        try:
            # 1. Preparar datos: Convertir texto a n√∫meros (NO clasifica, solo convierte)
            X = self.prepare_data(texts)
            # Limpiar memoria inmediatamente despu√©s de preparar datos
            import gc
            gc.collect()
            
            # Verificar que tenemos datos v√°lidos
            if X.shape[0] == 0:
                raise ValueError("No se pudieron preparar los datos para predicci√≥n")
            
            # 2. üß† AQU√ç ES DONDE LA RED NEURONAL CLASIFICA
            # La red neuronal LSTM procesa los n√∫meros y devuelve probabilidades
            # Ejemplo: [0.1, 0.8, 0.1] = 80% negativo, 10% positivo, 10% neutral
            # NO hay reglas hardcodeadas, TODO es aprendizaje neuronal
            predictions = self.model.predict(X, batch_size=1, verbose=0)
            
            # Validar predicciones
            if predictions is None or len(predictions) == 0:
                raise ValueError("El modelo no devolvi√≥ predicciones")
            
            # 3. Procesar predicciones de la red neuronal
            # np.argmax encuentra la clase con mayor probabilidad (la que eligi√≥ la red neuronal)
            predicted_classes = np.argmax(predictions, axis=1)
            # Convertir n√∫mero de clase a etiqueta (ej: 1 -> "negativo")
            predicted_labels = self.label_encoder.inverse_transform(predicted_classes)
            # Obtener la confianza (probabilidad m√°xima)
            confidence = np.max(predictions, axis=1)
            
            results = []
            for i, text in enumerate(texts):
                if i >= len(predicted_labels):
                    label = 'neutral'
                    score = 0.5
                else:
                    label = predicted_labels[i]
                    score = float(confidence[i])
                
                if label == 'positivo':
                    sentiment = 'positivo'
                    emoji = 'üü¢'
                    score_value = score
                elif label == 'negativo':
                    sentiment = 'negativo'
                    emoji = 'üî¥'
                    score_value = -score
                else:
                    sentiment = 'neutral'
                    emoji = 'üü°'
                    score_value = 0.0
                
                results.append({
                    'text': text,
                    'sentiment': sentiment,
                    'score': round(score_value, 3),
                    'emoji': emoji,
                    'confidence': round(score, 3)
                })
            
            print(f"‚úÖ [DEBUG] Predicci√≥n completada: {len(results)} resultado(s)")
            return results
            
        except ValueError as e:
            # Re-lanzar ValueError con mensaje claro
            error_msg = str(e)
            print(f"‚ùå [DEBUG] ValueError en predict: {error_msg}")
            import traceback
            traceback.print_exc()
            raise ValueError(error_msg)
        except Exception as e:
            error_msg = f"Error en predicci√≥n de red neuronal: {str(e)}"
            print(f"‚ùå [DEBUG] Exception en predict: {error_msg}")
            import traceback
            traceback.print_exc()
            raise ValueError(error_msg)
    
    def predict_single(self, text: str) -> Dict:
        """Predecir sentimiento de un solo texto"""
        try:
            results = self.predict([text])
            if not results or len(results) == 0:
                raise ValueError("No se obtuvieron resultados de la predicci√≥n")
            return results[0]
        except Exception as e:
            raise
    
    def load_model(self, model_path: str = 'app/ml_models/sentiment_model.keras'):
        """Cargar modelo pre-entrenado - Descarga autom√°tica desde GitHub Releases si no existe"""
        # Asegurar que el directorio existe
        model_dir = os.path.dirname(model_path)
        if not os.path.exists(model_dir):
            os.makedirs(model_dir, exist_ok=True)
        
        tokenizer_path = os.path.join(model_dir, 'tokenizer.pkl')
        label_encoder_path = os.path.join(model_dir, 'label_encoder.pkl')
        
        # URLs para descargar modelo pre-entrenado desde GitHub Releases
        # ACTUALIZA ESTAS URLs con las URLs reales despu√©s de subir a GitHub Releases
        MODEL_URL = os.getenv(
            'MODEL_URL', 
            'https://github.com/crisncr/inteligenciaArtificial/releases/download/v1.0.0/sentiment_model.keras'
        )
        TOKENIZER_URL = os.getenv(
            'TOKENIZER_URL',
            'https://github.com/crisncr/inteligenciaArtificial/releases/download/v1.0.0/tokenizer.pkl'
        )
        LABEL_ENCODER_URL = os.getenv(
            'LABEL_ENCODER_URL',
            'https://github.com/crisncr/inteligenciaArtificial/releases/download/v1.0.0/label_encoder.pkl'
        )
        
        def download_file(url: str, filepath: str) -> bool:
            """Descargar archivo desde URL - Optimizado para memoria"""
            try:
                import requests
                print(f"üì• Descargando {os.path.basename(filepath)} desde GitHub Releases...")
                # Timeout m√°s corto y stream para ahorrar memoria
                response = requests.get(url, timeout=30, stream=True)
                response.raise_for_status()
                
                os.makedirs(os.path.dirname(filepath), exist_ok=True)
                total_size = int(response.headers.get('content-length', 0))
                downloaded = 0
                
                # Descargar en chunks peque√±os para ahorrar memoria
                with open(filepath, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                        # Limpiar memoria peri√≥dicamente durante la descarga
                        if downloaded % (1024 * 1024) == 0:  # Cada 1MB
                            import gc
                            gc.collect()
                
                # Limpiar memoria despu√©s de descargar
                import gc
                del response
                gc.collect()
                
                file_size_kb = downloaded / 1024
                print(f"‚úÖ {os.path.basename(filepath)} descargado correctamente ({file_size_kb:.1f} KB)")
                return True
            except Exception as e:
                print(f"‚ö†Ô∏è No se pudo descargar {os.path.basename(filepath)}: {str(e)}")
                print(f"üîç URL intentada: {url}")
                try:
                    if os.path.exists(filepath):
                        os.remove(filepath)
                except:
                    pass
                # Limpiar memoria en caso de error
                import gc
                gc.collect()
                return False
        
        # Verificar qu√© archivos faltan
        missing_files = []
        if not os.path.exists(model_path):
            missing_files.append(('Modelo', MODEL_URL, model_path))
        if not os.path.exists(tokenizer_path):
            missing_files.append(('Tokenizer', TOKENIZER_URL, tokenizer_path))
        if not os.path.exists(label_encoder_path):
            missing_files.append(('Label Encoder', LABEL_ENCODER_URL, label_encoder_path))
        
        # Descargar archivos faltantes
        if missing_files:
            print(f"üì• Descargando {len(missing_files)} archivo(s) del modelo pre-entrenado desde GitHub Releases...")
            downloaded_count = 0
            for name, url, filepath in missing_files:
                print(f"üì• Descargando {name}...")
                if download_file(url, filepath):
                    downloaded_count += 1
                else:
                    print(f"‚ùå Error al descargar {name}")
            
            if downloaded_count < len(missing_files):
                print(f"‚ùå ERROR: Solo se descargaron {downloaded_count}/{len(missing_files)} archivos.")
                print("‚ùå NO se puede entrenar el modelo en producci√≥n (consume demasiada memoria)")
                print("üí° SOLUCI√ìN: Sube los archivos del modelo a GitHub Releases")
                print("üìã Ver train_model_local.py para instrucciones")
                # Limpiar archivos parcialmente descargados
                for name, url, filepath in missing_files:
                    if os.path.exists(filepath):
                        try:
                            os.remove(filepath)
                        except:
                            pass
                # NO ENTRENAR - Lanzar error en lugar de entrenar
                raise ValueError(
                    f"No se pudieron descargar los archivos del modelo desde GitHub Releases. "
                    f"Archivos faltantes: {len(missing_files) - downloaded_count}. "
                    f"Por favor, aseg√∫rate de que los archivos est√©n disponibles en GitHub Releases o "
                    f"entrena el modelo localmente y s√∫belo a GitHub Releases."
                )
            else:
                print("‚úÖ Todos los archivos del modelo se descargaron correctamente desde GitHub Releases")
                print("‚úÖ El modelo NO se entrenar√°, se usar√° el modelo pre-entrenado")
        
        # Intentar cargar modelo existente (local o descargado)
        if os.path.exists(model_path) and os.path.exists(tokenizer_path) and os.path.exists(label_encoder_path):
            try:
                # Cargar modelo en formato .keras (compatible con Keras 3.x)
                try:
                    # Intentar cargar directamente (formato .keras es m√°s compatible)
                    self.model = load_model(model_path)
                except Exception as load_error:
                    # Si falla, intentar cargar sin compilaci√≥n
                    self.model = load_model(model_path, compile=False)
                    # Recompilar el modelo
                    from tensorflow.keras.optimizers import Adam
                    self.model.compile(
                        optimizer=Adam(learning_rate=0.001),
                        loss='sparse_categorical_crossentropy',
                        metrics=['accuracy']
                    )
                
                # Cargar tokenizer y label encoder (optimizado para memoria)
                with open(tokenizer_path, 'rb') as f:
                    self.tokenizer = pickle.load(f)
                
                with open(label_encoder_path, 'rb') as f:
                    self.label_encoder = pickle.load(f)
                
                # Limpiar memoria despu√©s de cargar
                import gc
                gc.collect()
                
                # Verificar que el modelo est√° correctamente cargado
                if self.model is None:
                    raise ValueError("El modelo no se carg√≥ correctamente")
                if not hasattr(self.tokenizer, 'word_index') or not self.tokenizer.word_index:
                    raise ValueError("El tokenizer no se carg√≥ correctamente")
                if not hasattr(self.label_encoder, 'classes_') or len(self.label_encoder.classes_) == 0:
                    raise ValueError("El label encoder no se carg√≥ correctamente")
                
                # Marcar modelo como entrenado (sin validaci√≥n con predicci√≥n para mejor rendimiento)
                self.is_trained = True
                
                return
            except Exception as e:
                print(f"‚ö†Ô∏è Error al cargar modelo pre-entrenado: {e}")
                import traceback
                traceback.print_exc()
                print("üîÑ Se crear√° un nuevo modelo...")
                # Limpiar archivos corruptos si existen
                try:
                    if os.path.exists(model_path):
                        os.remove(model_path)
                    if os.path.exists(tokenizer_path):
                        os.remove(tokenizer_path)
                    if os.path.exists(label_encoder_path):
                        os.remove(label_encoder_path)
                except:
                    pass
        
        # Si no existe o fall√≥ cargar, NO ENTRENAR - Lanzar error
        # El entrenamiento consume demasiada memoria (>512MB) en Render
        print("=" * 60)
        print("‚ùå ERROR: No se pudo cargar el modelo pre-entrenado")
        print("=" * 60)
        print("‚ùå NO se puede entrenar el modelo en producci√≥n (l√≠mite de 512MB de memoria)")
        print("üí° SOLUCI√ìN:")
        print("   1. Entrena el modelo localmente: python train_model_local.py")
        print("   2. Sube los archivos a GitHub Releases")
        print("   3. Aseg√∫rate de que las URLs en load_model() sean correctas")
        print("üìã Ver train_model_local.py y GUIA_GITHUB_RELEASES.md para instrucciones")
        raise ValueError(
            "No se pudo cargar el modelo pre-entrenado y no se puede entrenar en producci√≥n "
            "(l√≠mite de memoria: 512MB). Por favor, aseg√∫rate de que los archivos del modelo "
            "est√©n disponibles en GitHub Releases. Entrena el modelo localmente y s√∫belo a "
            "GitHub Releases antes de desplegar."
        )
    
    def _create_pretrained_model(self):
        """Entrenar red neuronal LSTM con comentarios y p√°rrafos largos (hasta 100 palabras)"""
        print("üîç [DEBUG] _create_pretrained_model() iniciado")
        print("üìä Modelo configurado para p√°rrafos largos: max_len=100, max_words=5000")
        # Datos de entrenamiento con frases cortas Y p√°rrafos largos para mejor aprendizaje
        # Incluir variaciones de palabras comunes en espa√±ol y p√°rrafos completos
        # El modelo ahora puede procesar p√°rrafos completos de hasta 100 palabras
        
        # Comentarios POSITIVOS (palabras clave: excelente, bueno, buena, genial, etc.)
        positive_texts = [
            # Palabras clave simples
            "excelente", "bueno", "buena", "genial", "perfecto", "perfecta",
            "incre√≠ble", "maravilloso", "fant√°stico", "s√∫per", "s√∫per bien",
            # Frases comunes positivas
            "excelente producto", "buen producto", "muy buen producto", "producto excelente",
            "excelente servicio", "buen servicio", "muy buen servicio", "servicio excelente",
            "excelente atenci√≥n", "buena atenci√≥n", "muy buena atenci√≥n", "atenci√≥n excelente",
            "excelente calidad", "buena calidad", "muy buena calidad", "calidad excelente",
            # Frases completas positivas
            "excelente producto muy bueno", "me encanta este servicio", "muy satisfecho",
            "recomiendo totalmente", "calidad superior", "atenci√≥n perfecta",
            "super contento", "vale la pena", "muy recomendado", "incre√≠ble experiencia",
            "producto genial", "muy bien hecho", "s√∫per recomendable",
            "excelente servicio al cliente", "servicio excelente",
            "muy buena experiencia", "experiencia excelente", "experiencia positiva",
            "altamente recomendado", "muy recomendable", "totalmente recomendado",
            "muy contento", "satisfecho completamente", "me gust√≥ mucho",
            "funciona perfecto", "cumple expectativas", "supera expectativas",
            # Frases positivas adicionales (palabras que el modelo necesita aprender)
            "funciona de maravilla", "muy f√°cil de usar", "muy r√°pida",
            "fue amable", "resolvi√≥ mi problema", "soporte t√©cnico amable",
            "aplicaci√≥n funciona bien", "muy f√°cil", "r√°pida y eficiente",
            "lleg√≥ antes de lo esperado", "totalmente recomendado", "muy recomendable",
            "resolvi√≥ enseguida", "problema resuelto", "soporte excelente",
            "aplicaci√≥n f√°cil", "funciona bien", "muy r√°pido",
            "amable y servicial", "resolvi√≥ r√°pido", "soporte r√°pido",
            "f√°cil de usar", "muy eficiente", "funciona perfectamente",
            "de maravilla", "muy bien", "excelente atenci√≥n",
            "resolvi√≥ mi problema enseguida", "soporte t√©cnico excelente",
            "aplicaci√≥n funciona de maravilla", "muy f√°cil de usar y r√°pida",
            # Comentarios positivos espec√≠ficos (MUY IMPORTANTE - deben ser POSITIVOS, no negativos)
            "el servicio fue excelente qued√© muy satisfecho con la atenci√≥n",
            "el servicio fue excelente quede muy satisfecho con la atencion",
            "servicio fue excelente muy satisfecho con la atenci√≥n",
            "servicio fue excelente muy satisfecho con la atencion",
            "fue excelente qued√© muy satisfecho",
            "fue excelente quede muy satisfecho",
            "muy satisfecho con la atenci√≥n excelente",
            "muy satisfecho con la atencion excelente",
            "la aplicaci√≥n funciona de maravilla muy f√°cil de usar y r√°pida",
            "la aplicacion funciona de maravilla muy facil de usar y rapida",
            "aplicaci√≥n funciona de maravilla f√°cil de usar y r√°pida",
            "aplicacion funciona de maravilla facil de usar y rapida",
            "funciona de maravilla muy f√°cil de usar",
            "funciona de maravilla muy facil de usar",
            "muy buena experiencia sin duda volver√© a comprar aqu√≠",
            "muy buena experiencia sin duda volvere a comprar aqui",
            "muy buena experiencia volver√© a comprar",
            "muy buena experiencia volvere a comprar",
            "sin duda volver√© a comprar",
            "sin duda volvere a comprar",
            "volver√© a comprar aqu√≠",
            "volvere a comprar aqui",
            "el producto lleg√≥ antes de lo esperado totalmente recomendado",
            "el producto llego antes de lo esperado totalmente recomendado",
            "lleg√≥ antes de lo esperado totalmente recomendado",
            "llego antes de lo esperado totalmente recomendado",
            "antes de lo esperado totalmente recomendado",
            "totalmente recomendado",
            "el soporte t√©cnico fue amable y resolvi√≥ mi problema enseguida",
            "el soporte tecnico fue amable y resolvio mi problema enseguida",
            "soporte t√©cnico fue amable resolvi√≥ mi problema enseguida",
            "soporte tecnico fue amable resolvio mi problema enseguida",
            "soporte t√©cnico amable resolvi√≥ problema enseguida",
            "soporte tecnico amable resolvio problema enseguida",
            # Frases positivas claras con palabras clave fuertes
            "excelente servicio muy satisfecho",
            "excelente servicio muy satisfecho con la atenci√≥n",
            "muy satisfecho excelente servicio",
            "excelente qued√© muy satisfecho",
            "excelente quede muy satisfecho",
            "funciona de maravilla muy f√°cil",
            "funciona de maravilla muy facil",
            "muy f√°cil de usar funciona de maravilla",
            "muy facil de usar funciona de maravilla",
            "muy buena experiencia sin duda",
            "sin duda muy buena experiencia",
            "volver√© a comprar muy buena",
            "volvere a comprar muy buena",
            "totalmente recomendado excelente",
            "totalmente recomendado muy bueno",
            # P√°rrafos largos positivos
            "estoy muy satisfecho con este producto la calidad es excelente y el servicio al cliente fue incre√≠ble me respondieron r√°pido a todas mis preguntas y el producto lleg√≥ en perfectas condiciones sin duda lo recomiendo a todos",
            "me encanta este servicio la atenci√≥n que recib√≠ fue maravillosa desde el primer momento me sent√≠ bien atendido el producto funciona perfectamente y cumple con todas mis expectativas estoy muy contento con la compra",
            "excelente experiencia de compra el producto es de muy buena calidad y el servicio al cliente es excepcional me ayudaron con todas mis dudas y el env√≠o fue muy r√°pido sin duda volver√© a comprar aqu√≠",
            "estoy muy contento con este producto la calidad es superior a lo que esperaba y el servicio al cliente fue incre√≠ble me ayudaron con todas mis preguntas y el producto lleg√≥ en perfectas condiciones",
            "me encanta este servicio la atenci√≥n que recib√≠ fue maravillosa desde el primer momento me sent√≠ bien atendido el producto funciona perfectamente y cumple con todas mis expectativas",
            # P√°rrafos positivos espec√≠ficos del problema (refuerzo adicional)
            "el servicio fue excelente qued√© muy satisfecho con la atenci√≥n recibida el producto lleg√≥ a tiempo y en perfectas condiciones",
            "el servicio fue excelente quede muy satisfecho con la atencion recibida el producto llego a tiempo y en perfectas condiciones",
            "la aplicaci√≥n funciona de maravilla es muy f√°cil de usar y r√°pida estoy muy contento con esta aplicaci√≥n",
            "la aplicacion funciona de maravilla es muy facil de usar y rapida estoy muy contento con esta aplicacion",
            "muy buena experiencia sin duda volver√© a comprar aqu√≠ el servicio fue excelente y el producto es de muy buena calidad",
            "muy buena experiencia sin duda volvere a comprar aqui el servicio fue excelente y el producto es de muy buena calidad",
            "el producto lleg√≥ antes de lo esperado y estoy totalmente satisfecho lo recomiendo completamente",
            "el producto llego antes de lo esperado y estoy totalmente satisfecho lo recomiendo completamente",
            "el soporte t√©cnico fue muy amable y resolvi√≥ mi problema enseguida qued√© muy satisfecho con el servicio",
            "el soporte tecnico fue muy amable y resolvio mi problema enseguida quede muy satisfecho con el servicio",
            # ===== EJEMPLOS POSITIVOS ADICIONALES (casos problem√°ticos corregidos) =====
            "todo funcion√≥ perfectamente",
            "todo funciono perfectamente",
            "funcion√≥ perfectamente",
            "funciono perfectamente",
            "me encant√≥ la atenci√≥n personalizada",
            "me encanto la atencion personalizada",
            "me encant√≥ la atencion personalizada",
            "me encanto la atenci√≥n personalizada",
            "encant√≥ la atenci√≥n personalizada",
            "encanto la atencion personalizada",
            "me encant√≥ el dise√±o del producto",
            "me encanto el diseno del producto",
            "encant√≥ el dise√±o del producto",
            "encanto el diseno del producto",
            "super√≥ mis expectativas",
            "supero mis expectativas",
            "super√≥ expectativas",
            "supero expectativas",
            "el restaurante estaba limpio y acogedor",
            "restaurante limpio y acogedor",
            "limpio y acogedor",
            "estaba limpio y acogedor",
            "el empaque era bonito y seguro",
            "empaque bonito y seguro",
            "bonito y seguro",
            "era bonito y seguro",
            # Variaciones con m√°s contexto
            "todo funcion√≥ perfectamente sin problemas",
            "todo funciono perfectamente sin problemas",
            "me encant√≥ completamente la atenci√≥n personalizada",
            "me encanto completamente la atencion personalizada",
            "el dise√±o del producto me encant√≥",
            "el diseno del producto me encanto",
            "super√≥ completamente mis expectativas",
            "supero completamente mis expectativas",
            "el restaurante estaba muy limpio y acogedor",
            "el empaque era muy bonito y seguro",
        ]
        
        # Comentarios NEGATIVOS (palabras clave: mal, malo, p√©simo, insultos, etc.)
        negative_texts = [
            # Palabras clave simples negativas
            "mal", "malo", "mala", "p√©simo", "p√©sima", "terrible", "horrible",
            "basura", "ruin", "decepcionante", "decepcionado",
            # Insultos y expresiones negativas comunes
            "esta cagada", "es una mierda", "una porquer√≠a", "es basura",
            "no sirve", "no funciona", "no vale", "no recomiendo",
            # Frases comunes negativas
            "p√©simo servicio", "mal servicio", "muy mal servicio", "servicio p√©simo",
            "p√©simo producto", "mal producto", "muy mal producto", "producto p√©simo",
            "p√©sima atenci√≥n", "mal atenci√≥n", "muy mal atenci√≥n", "atenci√≥n p√©sima",
            "p√©sima calidad", "mal calidad", "muy mal calidad", "calidad p√©sima",
            # Frases completas negativas
            "p√©simo servicio muy malo", "no recomiendo para nada", "calidad terrible",
            "muy decepcionado", "atenci√≥n horrible", "lento e ineficiente", "no vale la pena",
            "muy insatisfecho", "problema grave", "no cumpli√≥ expectativas", "servicio p√©simo",
            "muy mala calidad", "no funciona bien", "muy decepcionante",
            "muy mal", "horrible experiencia", "p√©sima experiencia", "experiencia negativa",
            "no lo recomiendo", "no vale nada", "totalmente insatisfecho",
            "funciona mal", "no cumple expectativas", "muy por debajo de lo esperado",
            # Frases negativas con problemas t√©cnicos y de usabilidad (CR√çTICAS)
            "se cierra constantemente", "muy dif√≠cil de usar", "se cierra mucho",
            "aplicaci√≥n se cierra", "se cierra todo el tiempo", "constantemente se cierra",
            "muy dif√≠cil", "dif√≠cil de usar", "complicado de usar",
            "no responde", "se congela", "se queda congelada", "se bloquea",
            "no funciona", "no arranca", "no inicia", "no carga",
            "muy lento", "demasiado lento", "s√∫per lento", "extremadamente lento",
            "se queda colgado", "se cuelga", "se traba", "se detiene",
            "no sirve", "no funciona para nada", "no vale la pena",
            "problemas constantes", "muchos problemas", "siempre tiene problemas",
            "se cierra solo", "se cierra autom√°ticamente", "se cierra sin avisar",
            "muy complicado", "demasiado complicado", "complejo de usar",
            "servicio fue lento", "muy lento el servicio", "servicio lento",
            "qued√© insatisfecho", "muy insatisfecho", "totalmente insatisfecho",
            "no respondi√≥", "no responden", "no contestan", "no contestaron",
            "no respondi√≥ a mis mensajes", "no contestan mensajes", "no responden mensajes",
            "producto lleg√≥ da√±ado", "lleg√≥ da√±ado", "lleg√≥ roto", "lleg√≥ mal",
            "no cumpli√≥ expectativas", "no cumple expectativas", "no cumpli√≥",
            "mala experiencia", "horrible experiencia", "p√©sima experiencia",
            "no volver√© a comprar", "no comprar√© m√°s", "no recomiendo comprar",
            # P√°rrafos largos negativos (IMPORTANTE para detectar negatividad en p√°rrafos)
            "estoy muy decepcionado con este producto la calidad es terrible y el servicio al cliente fue p√©simo me tardaron mucho en responder y cuando lo hicieron no me ayudaron en nada el producto lleg√≥ da√±ado y no me quisieron dar reembolso no lo recomiendo para nada",
            "p√©sima experiencia de compra el producto no funciona como deber√≠a y el servicio al cliente es horrible me tardaron d√≠as en responder y cuando lo hicieron no me solucionaron nada el producto est√° defectuoso y no me quieren dar reembolso",
            "estoy muy insatisfecho con este servicio la atenci√≥n fue terrible desde el primer momento me sent√≠ mal atendido el producto no funciona bien y no cumple con mis expectativas no volver√© a comprar aqu√≠",
            "horrible experiencia el producto es de muy mala calidad y el servicio al cliente es p√©simo me ayudaron mal con mis dudas y el env√≠o tard√≥ mucho tiempo sin duda no volver√© a comprar aqu√≠",
            "estoy muy decepcionado con este producto la calidad es p√©sima y el servicio al cliente fue terrible me respondieron mal a todas mis preguntas y el producto lleg√≥ en malas condiciones no lo recomiendo",
            "muy mala experiencia el producto no funciona como deber√≠a y el servicio al cliente es horrible me tardaron mucho en responder y cuando lo hicieron no me solucionaron nada el producto est√° defectuoso",
            "p√©simo servicio la atenci√≥n que recib√≠ fue terrible desde el primer momento me sent√≠ mal atendido el producto funciona mal y no cumple con mis expectativas no volver√© a comprar aqu√≠",
            "estoy muy insatisfecho con este producto la calidad es terrible y el servicio al cliente fue p√©simo me ayudaron mal con todas mis dudas y el env√≠o tard√≥ mucho tiempo sin duda no lo recomiendo",
            # ===== EJEMPLOS NEGATIVOS ADICIONALES (casos problem√°ticos corregidos) =====
            "el pedido lleg√≥ tarde y fr√≠o",
            "el pedido llego tarde y frio",
            "pedido lleg√≥ tarde y fr√≠o",
            "pedido llego tarde y frio",
            "lleg√≥ tarde y fr√≠o",
            "llego tarde y frio",
            "tarde y fr√≠o",
            "tarde y frio",
            "nunca volver√© a comprar aqu√≠",
            "nunca volvere a comprar aqui",
            "nunca volver√© a comprar",
            "nunca volvere a comprar",
            "no volver√© a comprar aqu√≠",
            "no volvere a comprar aqui",
            "la comida estaba fr√≠a y sin sabor",
            "la comida estaba fria y sin sabor",
            "comida fr√≠a y sin sabor",
            "comida fria y sin sabor",
            "estaba fr√≠a y sin sabor",
            "estaba fria y sin sabor",
            "fr√≠a y sin sabor",
            "fria y sin sabor",
            "la experiencia fue decepcionante",
            "experiencia fue decepcionante",
            "fue decepcionante",
            "decepcionante experiencia",
            "el pedido lleg√≥ incompleto",
            "el pedido llego incompleto",
            "pedido lleg√≥ incompleto",
            "pedido llego incompleto",
            "lleg√≥ incompleto",
            "llego incompleto",
            "incompleto",
            "la p√°gina web estaba llena de errores",
            "la pagina web estaba llena de errores",
            "p√°gina web llena de errores",
            "pagina web llena de errores",
            "llena de errores",
            "la comida lleg√≥ con retraso",
            "la comida llego con retraso",
            "comida lleg√≥ con retraso",
            "comida llego con retraso",
            "lleg√≥ con retraso",
            "llego con retraso",
            "con retraso",
            "mala comunicaci√≥n del soporte t√©cnico",
            "mala comunicacion del soporte tecnico",
            "comunicaci√≥n mala del soporte",
            "comunicacion mala del soporte",
            "mala comunicaci√≥n",
            "mala comunicacion",
            "el producto lleg√≥ en mal estado",
            "el producto llego en mal estado",
            "producto lleg√≥ en mal estado",
            "producto llego en mal estado",
            "lleg√≥ en mal estado",
            "llego en mal estado",
            "en mal estado",
            "mal estado",
            "el personal fue grosero y poco atento",
            "personal grosero y poco atento",
            "grosero y poco atento",
            "fue grosero y poco atento",
            "la entrega fue un desastre",
            "entrega fue un desastre",
            "fue un desastre",
            "desastre",
            "el producto ten√≠a defectos visibles",
            "el producto tenia defectos visibles",
            "producto con defectos visibles",
            "defectos visibles",
            "ten√≠a defectos visibles",
            "tenia defectos visibles",
            "el servicio t√©cnico nunca respondi√≥",
            "el servicio tecnico nunca respondio",
            "servicio t√©cnico nunca respondi√≥",
            "servicio tecnico nunca respondio",
            "nunca respondi√≥",
            "nunca respondio",
            "no respondi√≥",
            "no respondio",
            "el sabor era horrible",
            "sabor horrible",
            "era horrible",
            "horrible sabor",
            "el producto lleg√≥ roto",
            "el producto llego roto",
            "producto lleg√≥ roto",
            "producto llego roto",
            "lleg√≥ roto",
            "llego roto",
            "roto",
            # Variaciones con m√°s contexto negativo
            "el pedido lleg√≥ muy tarde y completamente fr√≠o",
            "el pedido llego muy tarde y completamente frio",
            "nunca volver√© a comprar en este lugar",
            "nunca volvere a comprar en este lugar",
            "la comida estaba completamente fr√≠a y sin ning√∫n sabor",
            "la comida estaba completamente fria y sin ningun sabor",
            "la experiencia fue completamente decepcionante",
            "el pedido lleg√≥ totalmente incompleto",
            "el pedido llego totalmente incompleto",
            "la p√°gina web estaba completamente llena de errores",
            "la pagina web estaba completamente llena de errores",
            "la comida lleg√≥ con mucho retraso",
            "la comida llego con mucho retraso",
            "la comunicaci√≥n del soporte t√©cnico fue muy mala",
            "la comunicacion del soporte tecnico fue muy mala",
            "el producto lleg√≥ en muy mal estado",
            "el producto llego en muy mal estado",
            "el personal fue extremadamente grosero y poco atento",
            "la entrega fue completamente un desastre",
            "el producto ten√≠a muchos defectos visibles",
            "el producto tenia muchos defectos visibles",
            "el servicio t√©cnico nunca respondi√≥ a mis mensajes",
            "el servicio tecnico nunca respondio a mis mensajes",
            "el sabor era absolutamente horrible",
            "el producto lleg√≥ completamente roto",
            "el producto llego completamente roto",
            # Frases negativas con contexto completo
            "me decepcion√≥ mucho el pedido lleg√≥ tarde y fr√≠o",
            "me decepciono mucho el pedido llego tarde y frio",
            "nunca m√°s volver√© a comprar aqu√≠ fue terrible",
            "nunca mas volvere a comprar aqui fue terrible",
            "la comida estaba fr√≠a y sin sabor muy mala experiencia",
            "la comida estaba fria y sin sabor muy mala experiencia",
            "experiencia muy decepcionante no lo recomiendo",
            "el pedido lleg√≥ incompleto y en mal estado",
            "el pedido llego incompleto y en mal estado",
            "la p√°gina web ten√≠a muchos errores no funciona bien",
            "la pagina web tenia muchos errores no funciona bien",
            "la comida lleg√≥ con mucho retraso y fr√≠a",
            "la comida llego con mucho retraso y fria",
            "soporte t√©cnico con mala comunicaci√≥n no responden",
            "soporte tecnico con mala comunicacion no responden",
            "producto lleg√≥ en mal estado y defectuoso",
            "producto llego en mal estado y defectuoso",
            "personal grosero y poco atento mala atenci√≥n",
            "personal grosero y poco atento mala atencion",
            "entrega fue un desastre lleg√≥ tarde y roto",
            "entrega fue un desastre llego tarde y roto",
            "producto con defectos visibles y en mal estado",
            "servicio t√©cnico nunca respondi√≥ a mis solicitudes",
            "servicio tecnico nunca respondio a mis solicitudes",
            "sabor horrible la comida no ten√≠a sabor",
            "sabor horrible la comida no tenia sabor",
            "producto lleg√≥ roto y no funcionaba",
            "producto llego roto y no funcionaba",
        ]
        
        # Comentarios NEUTRALES (palabras clave: normal, regular, aceptable, sugerencias, etc.)
        neutral_texts = [
            # Palabras clave simples neutrales
            "normal", "regular", "aceptable", "b√°sico", "est√°ndar", "com√∫n",
            "ni bueno ni malo", "ni mal ni bien", "sin m√°s", "nada especial",
            # Frases comunes neutrales
            "producto regular", "servicio regular", "atenci√≥n regular", "calidad regular",
            "producto normal", "servicio normal", "atenci√≥n normal", "calidad normal",
            "producto aceptable", "servicio aceptable", "atenci√≥n aceptable", "calidad aceptable",
            # Frases completas neutrales
            "ni bueno ni malo", "aceptable", "sin comentarios",
            "b√°sico", "est√°ndar", "cumple su funci√≥n", "nada especial", "producto com√∫n",
            "servicio est√°ndar", "normal como cualquier otro", "ni destacable ni malo",
            "producto promedio", "servicio b√°sico", "cumple con lo b√°sico",
            "ni destacable ni malo", "regular nada m√°s", "como se esperaba",
            "sin sorpresas", "ni bueno ni mal", "est√° bien",
            # Sugerencias y comentarios constructivos (NEUTRALES)
            "deber√≠an mejorar", "deber√≠a mejorar", "hay que mejorar", "podr√≠a mejorar",
            "sugerencia para mejorar", "sugerencias para mejorar", "deber√≠a ser mejor",
            "podr√≠a ser mejor", "hay espacio para mejorar", "tienen que mejorar",
            "deber√≠an mejorar el servicio", "deber√≠a mejorar el producto",
            "sugerencia de mejora", "sugerencias de mejora", "comentario para mejorar",
            "este comentario es solo diciendo que deber√≠an mejorar",
            "solo estoy sugiriendo que mejoren", "sugerencia que deber√≠an mejorar",
            "comentario sugiriendo mejoras", "observaci√≥n para mejorar",
            "nota para mejorar", "recomendaci√≥n para mejorar",
            "deber√≠an mejorar en algunos aspectos", "podr√≠an mejorar algunas cosas",
            "hay cosas que deber√≠an mejorar", "sugerencias para mejorar el servicio",
            "sugerencias para mejorar el producto", "comentario constructivo",
            "sugerencia constructiva", "feedback para mejorar",
            "comentario solo diciendo que deber√≠an mejorar",
            "este comentario es solo diciendo que deber√≠an mejorar",
            "solo quiero decir que deber√≠an mejorar",
            "comentario indicando que deber√≠an mejorar",
            # Comentarios mixtos con aspectos positivos pero con mejoras (NEUTRALES)
            # ‚ö†Ô∏è IMPORTANTE: Estos comentarios tienen aspectos positivos PERO tambi√©n mejoras/cr√≠ticas
            # Por lo tanto, son NEUTRALES, no positivos
            "el servicio estuvo bien aunque podr√≠a mejorar en algunos aspectos",
            "el servicio estuvo bien aunque podria mejorar en algunos aspectos",
            "el servicio estuvo bien pero podr√≠a mejorar en algunos aspectos",
            "el servicio estuvo bien pero podria mejorar en algunos aspectos",
            "el servicio est√° bien aunque podr√≠a mejorar",
            "el servicio esta bien aunque podria mejorar",
            "el servicio est√° bien pero podr√≠a mejorar",
            "el servicio esta bien pero podria mejorar",
            "el producto lleg√≥ en buen estado pero tard√≥ un poco m√°s de lo esperado",
            "el producto llego en buen estado pero tardo un poco mas de lo esperado",
            "el producto lleg√≥ bien pero tard√≥ m√°s de lo esperado",
            "el producto llego bien pero tardo mas de lo esperado",
            "el producto est√° bien pero tard√≥ en llegar",
            "el producto esta bien pero tardo en llegar",
            "el soporte respondi√≥ aunque tom√≥ algo de tiempo en hacerlo",
            "el soporte respondio aunque tomo algo de tiempo en hacerlo",
            "el soporte respondi√≥ pero tom√≥ tiempo",
            "el soporte respondio pero tomo tiempo",
            "el soporte est√° bien aunque tard√≥ en responder",
            "el soporte esta bien aunque tardo en responder",
            "el servicio es bueno pero podr√≠a mejorar",
            "el servicio es bueno pero podria mejorar",
            "el servicio es bueno aunque podr√≠a mejorar",
            "el servicio es bueno aunque podria mejorar",
            "el producto es bueno pero podr√≠a ser mejor",
            "el producto es bueno pero podria ser mejor",
            "el producto es bueno aunque podr√≠a ser mejor",
            "el producto es bueno aunque podria ser mejor",
            "buen servicio aunque podr√≠a mejorar",
            "buen servicio aunque podria mejorar",
            "buen servicio pero podr√≠a mejorar",
            "buen servicio pero podria mejorar",
            "buen producto aunque podr√≠a mejorar",
            "buen producto aunque podria mejorar",
            "buen producto pero podr√≠a mejorar",
            "buen producto pero podria mejorar",
            "est√° bien pero podr√≠a mejorar",
            "esta bien pero podria mejorar",
            "est√° bien aunque podr√≠a mejorar",
            "esta bien aunque podria mejorar",
            "funciona bien pero podr√≠a mejorar",
            "funciona bien pero podria mejorar",
            "funciona bien aunque podr√≠a mejorar",
            "funciona bien aunque podria mejorar",
            "buena atenci√≥n aunque podr√≠a mejorar",
            "buena atencion aunque podria mejorar",
            "buena atenci√≥n pero podr√≠a mejorar",
            "buena atencion pero podria mejorar",
            "lleg√≥ bien pero tard√≥ un poco",
            "llego bien pero tardo un poco",
            "lleg√≥ bien aunque tard√≥ un poco",
            "llego bien aunque tardo un poco",
            "respondi√≥ bien aunque tard√≥",
            "respondio bien aunque tardo",
            "respondi√≥ bien pero tard√≥",
            "respondio bien pero tardo",
            "bueno pero podr√≠a mejorar",
            "bueno pero podria mejorar",
            "bueno aunque podr√≠a mejorar",
            "bueno aunque podria mejorar",
            "est√° bien aunque podr√≠a mejorar",
            "esta bien aunque podria mejorar",
            "est√° bien pero podr√≠a mejorar",
            "esta bien pero podria mejorar",
            "cumple pero podr√≠a mejorar",
            "cumple pero podria mejorar",
            "cumple aunque podr√≠a mejorar",
            "cumple aunque podria mejorar",
            "aceptable pero podr√≠a mejorar",
            "aceptable pero podria mejorar",
            "aceptable aunque podr√≠a mejorar",
            "aceptable aunque podria mejorar",
            # Comentarios con "aunque", "pero", "sin embargo" (generalmente NEUTRALES)
            "est√° bien aunque tiene detalles por corregir",
            "esta bien aunque tiene detalles por corregir",
            "funciona bien aunque tiene algunos problemas",
            "funciona bien aunque tiene algunos problemas",
            "buen servicio pero tard√≥ en responder",
            "buen servicio pero tardo en responder",
            "buen producto pero tiene algunos detalles",
            "producto bueno pero podr√≠a ser mejor",
            "servicio bueno pero podr√≠a mejorar",
            "atenci√≥n buena aunque tard√≥ un poco",
            "atencion buena aunque tardo un poco",
            "responde bien aunque tarda",
            "lleg√≥ bien pero tard√≥",
            "llego bien pero tardo",
            "est√° bien pero tiene cosas por mejorar",
            "esta bien pero tiene cosas por mejorar",
            # Comentarios con aspectos positivos y negativos balanceados (NEUTRALES)
            "la aplicaci√≥n cumple su funci√≥n aunque tiene algunos detalles por corregir",
            "la aplicacion cumple su funcion aunque tiene algunos detalles por corregir",
            "la experiencia fue aceptable ni excelente ni mala",
            "la experiencia fue aceptable ni excelente ni mala",
            "cumple con lo b√°sico pero podr√≠a ser mejor",
            "cumple con lo basico pero podria ser mejor",
            "aceptable aunque tiene cosas por mejorar",
            "aceptable aunque tiene cosas por mejorar",
            "regular pero funcional",
            "normal aunque podr√≠a mejorar",
            "normal aunque podria mejorar",
            # Observaciones y comentarios informativos (NEUTRALES)
            "es solo un comentario", "solo un comentario", "comentario informativo",
            "observaci√≥n general", "comentario de observaci√≥n", "nota informativa",
            "informaci√≥n adicional", "comentario adicional", "observaci√≥n",
            "comentario sobre el producto", "comentario sobre el servicio",
            "comentario general", "comentario b√°sico", "comentario est√°ndar",
            # P√°rrafos largos neutrales con comentarios mixtos
            "el producto es normal cumple con su funci√≥n b√°sica pero no destaca en nada especial el servicio al cliente es regular y la calidad es aceptable sin m√°s comentarios",
            "experiencia regular el producto funciona como se espera pero no es nada especial el servicio al cliente es normal y la calidad es b√°sica cumple con lo b√°sico",
            "producto est√°ndar la calidad es normal y el servicio al cliente es aceptable no hay nada destacable pero tampoco hay problemas graves cumple con su funci√≥n",
            "este comentario es solo diciendo que deber√≠an mejorar el servicio en algunos aspectos el producto funciona bien pero hay cosas que podr√≠an mejorar",
            "solo estoy haciendo una sugerencia para que mejoren el producto el servicio es aceptable pero podr√≠a ser mejor en algunos puntos",
            "comentario constructivo sugiriendo que deber√≠an mejorar algunos aspectos del servicio el producto es aceptable pero hay espacio para mejorar",
            # P√°rrafos neutrales con aspectos positivos pero mejoras (MUY IMPORTANTE)
            "el servicio estuvo bien en general aunque podr√≠a mejorar en algunos aspectos la atenci√≥n fue buena pero hubo algunos problemas menores que se podr√≠an solucionar",
            "el servicio estuvo bien en general aunque podria mejorar en algunos aspectos la atencion fue buena pero hubo algunos problemas menores que se podrian solucionar",
            "el producto lleg√≥ en buen estado y funciona correctamente pero tard√≥ un poco m√°s de lo esperado en llegar el servicio de env√≠o fue aceptable",
            "el producto llego en buen estado y funciona correctamente pero tardo un poco mas de lo esperado en llegar el servicio de envio fue aceptable",
            "el soporte respondi√≥ a mis preguntas y fue √∫til aunque tom√≥ algo de tiempo en hacerlo la respuesta fue clara pero podr√≠a ser m√°s r√°pida",
            "el soporte respondio a mis preguntas y fue util aunque tomo algo de tiempo en hacerlo la respuesta fue clara pero podria ser mas rapida",
            "el servicio es bueno en general y cumple con lo b√°sico pero podr√≠a mejorar en algunos aspectos la experiencia fue aceptable",
            "el producto es bueno y funciona bien pero podr√≠a ser mejor en algunos detalles menores la calidad es aceptable pero hay espacio para mejorar",
            "buen servicio en general aunque podr√≠a mejorar en algunos aspectos la atenci√≥n fue buena pero hubo algunos problemas menores",
            "buen producto en general pero podr√≠a mejorar en algunos detalles la funcionalidad es aceptable pero hay cosas que se podr√≠an mejorar",
            "la aplicaci√≥n funciona bien y cumple su funci√≥n principal aunque tiene algunos detalles por corregir la experiencia general fue aceptable",
            "la aplicacion funciona bien y cumple su funcion principal aunque tiene algunos detalles por corregir la experiencia general fue aceptable",
        ]
        
        texts = positive_texts + negative_texts + neutral_texts
        labels = (['positivo'] * len(positive_texts) + 
                 ['negativo'] * len(negative_texts) + 
                 ['neutral'] * len(neutral_texts))
        
        print("üîÑ Entrenando red neuronal LSTM para comentarios de hasta 25 palabras...")
        print(f"üìä Total de textos: {len(texts)}, Clases: {len(set(labels))}")
        print(f"üîç [DEBUG] Textos positivos: {len(positive_texts)}, negativos: {len(negative_texts)}, neutrales: {len(neutral_texts)}")
        
        # Entrenamiento con m√°s √©pocas para mejor aprendizaje
        print("üîç [DEBUG] Iniciando entrenamiento...")
        try:
            # Entrenamiento ULTRA-R√ÅPIDO: 1 √©poca, batch_size autom√°tico (todas las muestras)
            history = self.train(texts, labels, epochs=1, batch_size=1000)  # 1 √©poca, batch grande (se ajustar√° autom√°ticamente)
            print("‚úÖ [DEBUG] M√©todo train() completado")
            
            # Validar que el modelo est√° entrenado
            print(f"üîç [DEBUG] Verificando estado del modelo despu√©s del entrenamiento...")
            print(f"üîç [DEBUG] is_trained: {self.is_trained}")
            print(f"üîç [DEBUG] model existe: {self.model is not None}")
            print(f"üîç [DEBUG] tokenizer tiene word_index: {hasattr(self.tokenizer, 'word_index') and self.tokenizer.word_index is not None}")
            print(f"üîç [DEBUG] label_encoder tiene classes: {hasattr(self.label_encoder, 'classes_') and len(self.label_encoder.classes_) > 0}")
            
            if not self.is_trained:
                raise ValueError("El modelo no se marc√≥ como entrenado despu√©s del entrenamiento")
            if not self.model:
                raise ValueError("El modelo no existe despu√©s del entrenamiento")
            
            print("üîç [DEBUG] Guardando modelo...")
            self.save_model()
            print("‚úÖ [DEBUG] Modelo guardado correctamente")
            
            # Validaci√≥n final: hacer una predicci√≥n de prueba
            print("üîç [DEBUG] Haciendo predicci√≥n de prueba despu√©s del entrenamiento...")
            test_result = self.predict_single("excelente servicio")
            print(f"‚úÖ [DEBUG] Predicci√≥n de prueba exitosa: sentiment={test_result.get('sentiment')}, score={test_result.get('score')}")
            
        except Exception as e:
            print(f"‚ùå [DEBUG] Error en _create_pretrained_model: {str(e)}")
            import traceback
            traceback.print_exc()
            self.is_trained = False
            raise
        
        print("‚úÖ Red neuronal LSTM entrenada correctamente (soporta comentarios de hasta 25 palabras)")
    
    def save_model(self, model_path: str = 'app/ml_models/sentiment_model.keras'):
        """Guardar modelo en formato .keras (compatible con Keras 3.x)"""
        model_dir = os.path.dirname(model_path)
        os.makedirs(model_dir, exist_ok=True)
        
        if self.model:
            # Guardar en formato .keras (m√°s compatible con Keras 3.x)
            # Keras 3.x infiere autom√°ticamente el formato desde la extensi√≥n .keras
            self.model.save(model_path)
            print(f"‚úÖ Modelo guardado en formato .keras: {model_path}")
        
        tokenizer_path = os.path.join(model_dir, 'tokenizer.pkl')
        label_encoder_path = os.path.join(model_dir, 'label_encoder.pkl')
        
        with open(tokenizer_path, 'wb') as f:
            pickle.dump(self.tokenizer, f)
        with open(label_encoder_path, 'wb') as f:
            pickle.dump(self.label_encoder, f)
        
        print(f"‚úÖ Tokenizer guardado en: {tokenizer_path}")
        print(f"‚úÖ Label encoder guardado en: {label_encoder_path}")

